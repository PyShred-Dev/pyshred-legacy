{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from misc.example_helper import *\n",
    "import importlib\n",
    "import processing\n",
    "import models\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "importlib.reload(processing)\n",
    "importlib.reload(models)\n",
    "from processing.parametric_data_manager import ParametricSHREDDataManager\n",
    "from models.shred_models import SHRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor summary                       sensor type location/trajectory\n",
      "0  stationary (randomly selected)               (17,)\n",
      "1  stationary (randomly selected)               (55,)\n",
      "2      stationary (user selected)                (0,)\n",
      "3      stationary (user selected)                (1,)\n",
      "6\n",
      "compressed full_state_data: (70350, 20)\n",
      "done generating dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialize ParametricSHREDDataManager\n",
    "manager = ParametricSHREDDataManager(\n",
    "    lags = 20,\n",
    "    train_size = 0.7,\n",
    "    val_size = 0.15,\n",
    "    test_size = 0.15,\n",
    "    scaling = \"minmax\",\n",
    "    compression = 20,\n",
    "    time=np.arange(0, 201),\n",
    "    )\n",
    "\n",
    "# Add data to manager (with sensors)\n",
    "dataset = np.load('kuramoto_sivashinsky\\KuramotoSivashinsky_data.npz')\n",
    "data = dataset['u'] # shape (500, 201, 100)\n",
    "mu = dataset['mu'] # shape (500, 201, 2)\n",
    "mobile_sensors = [\n",
    "    forward_backward_walk(start=0, end = data.shape[2], timesteps=data.shape[1], forward_first=True),\n",
    "    forward_backward_walk(start=0, end = data.shape[2], timesteps=data.shape[1], forward_first=False),\n",
    "]\n",
    "\n",
    "manager.add(\n",
    "    data=data,\n",
    "    random_sensors=2,\n",
    "    stationary_sensors=[(0,), (1,)],\n",
    "    # mobile_sensors=mobile_sensors,\n",
    "    params=mu,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shapes:\n",
      "Reconstructor Data\n",
      "train X: torch.Size([70350, 21, 6])\n",
      "train Y: torch.Size([70350, 20])\n",
      "valid X: torch.Size([15075, 21, 6])\n",
      "valid Y: torch.Size([15075, 20])\n",
      "test X: torch.Size([15075, 21, 6])\n",
      "test Y: torch.Size([15075, 20])\n"
     ]
    }
   ],
   "source": [
    "# Get train/valid/test datasets\n",
    "train_set, valid_set, test_set = manager.preprocess()\n",
    "\n",
    "# Print dataset shapes\n",
    "print('Data Shapes:')\n",
    "print ('Reconstructor Data')\n",
    "print('train X:', train_set.reconstructor.X.shape)\n",
    "print('train Y:', train_set.reconstructor.Y.shape)\n",
    "print('valid X:', valid_set.reconstructor.X.shape)\n",
    "print('valid Y:', valid_set.reconstructor.Y.shape)\n",
    "print('test X:', test_set.reconstructor.X.shape)\n",
    "print('test Y:', test_set.reconstructor.Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.7233])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.reconstructor.X[201,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newest Version\n",
      "looking good\n",
      "looking good\n",
      "\n",
      "Fitting Reconstructor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1100/1100 [00:11<00:00, 95.36batch/s, loss=0.00928, L2=0.203, val_loss=0.00417, val_L2=0.142] \n",
      "Epoch 2/10: 100%|██████████| 1100/1100 [00:10<00:00, 102.60batch/s, loss=0.00455, L2=0.147, val_loss=0.00345, val_L2=0.129]\n",
      "Epoch 3/10: 100%|██████████| 1100/1100 [00:10<00:00, 101.64batch/s, loss=0.00357, L2=0.131, val_loss=0.00268, val_L2=0.114]\n",
      "Epoch 4/10: 100%|██████████| 1100/1100 [00:10<00:00, 100.92batch/s, loss=0.00305, L2=0.121, val_loss=0.0024, val_L2=0.108]\n",
      "Epoch 5/10: 100%|██████████| 1100/1100 [00:11<00:00, 97.78batch/s, loss=0.0027, L2=0.114, val_loss=0.00196, val_L2=0.0972]\n",
      "Epoch 6/10: 100%|██████████| 1100/1100 [00:10<00:00, 104.50batch/s, loss=0.0024, L2=0.107, val_loss=0.00178, val_L2=0.0926]\n",
      "Epoch 7/10: 100%|██████████| 1100/1100 [00:10<00:00, 105.76batch/s, loss=0.00216, L2=0.101, val_loss=0.00162, val_L2=0.0883]\n",
      "Epoch 8/10: 100%|██████████| 1100/1100 [00:10<00:00, 106.13batch/s, loss=0.002, L2=0.0975, val_loss=0.00165, val_L2=0.0893]\n",
      "Epoch 9/10: 100%|██████████| 1100/1100 [00:10<00:00, 107.49batch/s, loss=0.00184, L2=0.0936, val_loss=0.00144, val_L2=0.0832]\n",
      "Epoch 10/10: 100%|██████████| 1100/1100 [00:10<00:00, 105.50batch/s, loss=0.0017, L2=0.09, val_loss=0.00153, val_L2=0.0859]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Reconstructor Validation Errors': array([0.14175616, 0.12896176, 0.113763  , 0.10759839, 0.09716538,\n",
       "        0.09256653, 0.08825097, 0.0892787 , 0.08320087, 0.08591171],\n",
       "       dtype=float32),\n",
       " 'Forecaster Validation Errors': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize SHRED\n",
    "shred = SHRED(sequence='LSTM', decoder='SDN')\n",
    "# fit SHRED\n",
    "shred.fit(train_set, valid_set, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15075, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = shred._reconstructor(test_set.reconstructor.X).detach().cpu().numpy()\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyshred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
