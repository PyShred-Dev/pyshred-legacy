{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyshred\n",
    "from pyshred.models import SHRED\n",
    "from pyshred.sequence_models import *\n",
    "from pyshred.decoder_models import *\n",
    "from pyshred.datasets import load_plasma # import plasma dataset\n",
    "from pyshred_pypi_helper import *\n",
    "import numpy as np\n",
    "from pyshred.data_processor import DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plasma_data = load_plasma()\n",
    "data_Jex = plasma_data['Jex']\n",
    "data_Jey = plasma_data['Jey']\n",
    "data_Jez = plasma_data['Jez']\n",
    "\n",
    "data = {\n",
    "    'Jex' : data_Jex,\n",
    "    'Jey' : data_Jey,\n",
    "    'Jez' : data_Jez,\n",
    "}\n",
    "\n",
    "Jez_mobile_clockwise_perimeter_walk_cw = perimeter_walk(height = data_Jez.shape[0], width = data_Jez.shape[1], timesteps = data_Jez.shape[2], clockwise=True)\n",
    "Jez_mobile_clockwise_perimeter_walk_ccw = perimeter_walk(height = data_Jez.shape[0], width = data_Jez.shape[1], timesteps = data_Jez.shape[2], clockwise=False)\n",
    "\n",
    "sensors = {\n",
    "    'Jez' : [Jez_mobile_clockwise_perimeter_walk_cw, Jez_mobile_clockwise_perimeter_walk_ccw], # mobile sensors\n",
    "    'Jey' : [(0,0), (49,59)], # selected stationary sensors\n",
    "    'Jex' : 3 # random stationary sensors\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate input\n",
      "Compressing Data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "shred_dataset = DataProcessor(data = data, sensors = sensors, time = None)\n",
    "recon_train_dataset, recon_val_dataset, recon_test_dataset, forecast_train_dataset, forecast_val_dataset, forecast_test_dataset = shred_dataset.prepare_datasets(val_size = 0.2, test_size = 0.2, lags = 20, n_components = 20)\n",
    "\n",
    "# want: train, val, test = shred_dataset.prepare_datasets(val_size = 0.2, test_size = 0.2, lags = 20, n_components = 20)\n",
    "\n",
    "# Next up:\n",
    "\n",
    "# this:\n",
    "# shred.fit(data, sensors, lags = 40, time = None, sensor_forecaster = True, n_components = 20, val_size = 0.2, batch_size=64, num_epochs=4000, lr=1e-3, verbose=True, patience=20):\n",
    "# to:\n",
    "# shred.fit(recon_train, recon_val, forecast_train, forecast_val, batch_size=64, num_epochs=4000, lr=1e-3, verbose=True, patience=20):\n",
    "\n",
    "# create a custom class that inside has multiple standard TimeSeriesDataset objects (wraps multiple together):\n",
    "# shred.fit(train, val, batch_size=64, num_epochs=4000, lr=1e-3, verbose=True, patience=20):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(self, data, sensors, lags = 40, time = None, sensor_forecaster = True, n_components = 20, val_size = 0.2, batch_size=64, num_epochs=4000, lr=1e-3, verbose=True, patience=20):\n",
    "\n",
    "# def fit(self, recon_train, recon_val, forecast_train, forecast_val, batch_size=64, num_epochs=4000, lr=1e-3, verbose=True, patience=20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Data...\n",
      "Done.\n",
      "\n",
      "Fitting Reconstructor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 25/25 [00:02<00:00,  8.74batch/s, loss=0.0678, L2=0.45, val_loss=0.0294, val_L2=0.317]\n",
      "Epoch 2/10: 100%|██████████| 25/25 [00:02<00:00,  8.39batch/s, loss=0.0322, L2=0.332, val_loss=0.0278, val_L2=0.308]\n",
      "Epoch 3/10: 100%|██████████| 25/25 [00:02<00:00,  8.61batch/s, loss=0.0304, L2=0.322, val_loss=0.0262, val_L2=0.299]\n",
      "Epoch 4/10: 100%|██████████| 25/25 [00:02<00:00,  8.65batch/s, loss=0.0288, L2=0.314, val_loss=0.0245, val_L2=0.289]\n",
      "Epoch 5/10: 100%|██████████| 25/25 [00:02<00:00,  8.33batch/s, loss=0.0275, L2=0.307, val_loss=0.0241, val_L2=0.287]\n",
      "Epoch 6/10: 100%|██████████| 25/25 [00:02<00:00,  8.93batch/s, loss=0.0261, L2=0.299, val_loss=0.0231, val_L2=0.281]\n",
      "Epoch 7/10: 100%|██████████| 25/25 [00:02<00:00,  9.23batch/s, loss=0.0253, L2=0.294, val_loss=0.0228, val_L2=0.279]\n",
      "Epoch 8/10: 100%|██████████| 25/25 [00:02<00:00,  9.09batch/s, loss=0.0247, L2=0.291, val_loss=0.0224, val_L2=0.277]\n",
      "Epoch 9/10: 100%|██████████| 25/25 [00:02<00:00,  8.47batch/s, loss=0.0244, L2=0.289, val_loss=0.0216, val_L2=0.272]\n",
      "Epoch 10/10: 100%|██████████| 25/25 [00:02<00:00,  8.67batch/s, loss=0.0236, L2=0.284, val_loss=0.0209, val_L2=0.267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting Forecaster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 25/25 [00:02<00:00,  8.51batch/s, loss=0.0702, L2=0.426, val_loss=0.0246, val_L2=0.268]\n",
      "Epoch 2/10: 100%|██████████| 25/25 [00:02<00:00,  8.51batch/s, loss=0.0262, L2=0.272, val_loss=0.0104, val_L2=0.174]\n",
      "Epoch 3/10: 100%|██████████| 25/25 [00:03<00:00,  8.29batch/s, loss=0.0162, L2=0.215, val_loss=0.00937, val_L2=0.165]\n",
      "Epoch 4/10: 100%|██████████| 25/25 [00:02<00:00,  8.80batch/s, loss=0.0131, L2=0.193, val_loss=0.00718, val_L2=0.145]\n",
      "Epoch 5/10: 100%|██████████| 25/25 [00:02<00:00,  8.80batch/s, loss=0.0118, L2=0.183, val_loss=0.00679, val_L2=0.141]\n",
      "Epoch 6/10: 100%|██████████| 25/25 [00:02<00:00,  8.99batch/s, loss=0.0108, L2=0.175, val_loss=0.00617, val_L2=0.134]\n",
      "Epoch 7/10: 100%|██████████| 25/25 [00:02<00:00,  9.08batch/s, loss=0.00979, L2=0.167, val_loss=0.00648, val_L2=0.138]\n",
      "Epoch 8/10: 100%|██████████| 25/25 [00:02<00:00,  8.94batch/s, loss=0.00914, L2=0.161, val_loss=0.00591, val_L2=0.131]\n",
      "Epoch 9/10: 100%|██████████| 25/25 [00:02<00:00,  9.04batch/s, loss=0.00835, L2=0.154, val_loss=0.00428, val_L2=0.112]\n",
      "Epoch 10/10: 100%|██████████| 25/25 [00:02<00:00,  8.91batch/s, loss=0.00766, L2=0.148, val_loss=0.00647, val_L2=0.138]\n"
     ]
    }
   ],
   "source": [
    "sequence_model = Transformer(d_model=64, num_encoder_layers=2, nhead=8, dropout=0.1)\n",
    "decoder_model = SDN(l1 = 200, l2 = 300, dropout= 0.2)\n",
    "shred = SHRED(sequence=sequence_model, decoder=decoder_model)\n",
    "val_errors,  sensor_forecast_errors = shred.fit(data = data, sensors = sensors, num_epochs=10) # by default: n_components = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shred = SHRED(sequence='LSTM', decoder='SDN')\n",
    "shred.fit(data = 'path_to_folder or file_path', sensors = 'default 3', lags = 'default 40', n_components='defuault 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Data...\n",
      "Done.\n",
      "\n",
      "Fitting Reconstructor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 25/25 [00:00<00:00, 90.42batch/s, loss=0.105, L2=0.554, val_loss=0.0342, val_L2=0.343]\n",
      "Epoch 2/10: 100%|██████████| 25/25 [00:00<00:00, 110.30batch/s, loss=0.0313, L2=0.328, val_loss=0.0267, val_L2=0.303]\n",
      "Epoch 3/10: 100%|██████████| 25/25 [00:00<00:00, 107.26batch/s, loss=0.0284, L2=0.313, val_loss=0.0253, val_L2=0.296]\n",
      "Epoch 4/10: 100%|██████████| 25/25 [00:00<00:00, 110.21batch/s, loss=0.0277, L2=0.309, val_loss=0.0249, val_L2=0.293]\n",
      "Epoch 5/10: 100%|██████████| 25/25 [00:00<00:00, 119.44batch/s, loss=0.027, L2=0.305, val_loss=0.0242, val_L2=0.289]\n",
      "Epoch 6/10: 100%|██████████| 25/25 [00:00<00:00, 114.99batch/s, loss=0.0261, L2=0.3, val_loss=0.0234, val_L2=0.284]\n",
      "Epoch 7/10: 100%|██████████| 25/25 [00:00<00:00, 115.51batch/s, loss=0.0256, L2=0.297, val_loss=0.0234, val_L2=0.284]\n",
      "Epoch 8/10: 100%|██████████| 25/25 [00:00<00:00, 110.10batch/s, loss=0.0253, L2=0.295, val_loss=0.0231, val_L2=0.282]\n",
      "Epoch 9/10: 100%|██████████| 25/25 [00:00<00:00, 116.39batch/s, loss=0.025, L2=0.293, val_loss=0.0228, val_L2=0.28]\n",
      "Epoch 10/10: 100%|██████████| 25/25 [00:00<00:00, 111.57batch/s, loss=0.0246, L2=0.291, val_loss=0.0223, val_L2=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting Forecaster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 25/25 [00:00<00:00, 109.19batch/s, loss=0.11, L2=0.54, val_loss=0.0398, val_L2=0.351]\n",
      "Epoch 2/10: 100%|██████████| 25/25 [00:00<00:00, 106.52batch/s, loss=0.0358, L2=0.332, val_loss=0.0239, val_L2=0.272]\n",
      "Epoch 3/10: 100%|██████████| 25/25 [00:00<00:00, 113.00batch/s, loss=0.0225, L2=0.264, val_loss=0.0148, val_L2=0.214]\n",
      "Epoch 4/10: 100%|██████████| 25/25 [00:00<00:00, 117.68batch/s, loss=0.0173, L2=0.231, val_loss=0.0116, val_L2=0.19]\n",
      "Epoch 5/10: 100%|██████████| 25/25 [00:00<00:00, 105.72batch/s, loss=0.0145, L2=0.211, val_loss=0.0102, val_L2=0.178]\n",
      "Epoch 6/10: 100%|██████████| 25/25 [00:00<00:00, 113.47batch/s, loss=0.0128, L2=0.199, val_loss=0.00932, val_L2=0.17]\n",
      "Epoch 7/10: 100%|██████████| 25/25 [00:00<00:00, 109.02batch/s, loss=0.0117, L2=0.19, val_loss=0.00875, val_L2=0.165]\n",
      "Epoch 8/10: 100%|██████████| 25/25 [00:00<00:00, 116.16batch/s, loss=0.0107, L2=0.182, val_loss=0.00739, val_L2=0.151]\n",
      "Epoch 9/10: 100%|██████████| 25/25 [00:00<00:00, 117.44batch/s, loss=0.00974, L2=0.174, val_loss=0.0067, val_L2=0.144]\n",
      "Epoch 10/10: 100%|██████████| 25/25 [00:00<00:00, 111.42batch/s, loss=0.00905, L2=0.167, val_loss=0.00604, val_L2=0.137]\n"
     ]
    }
   ],
   "source": [
    "sequence_model = LSTM(hidden_size=32, num_layers=1)\n",
    "decoder_model = SDN(l1 = 200, l2 = 300, dropout= 0.2)\n",
    "shred = SHRED(sequence=sequence_model, decoder=decoder_model)\n",
    "val_errors,  sensor_forecast_errors = shred.fit(data = data, sensors = sensors, num_epochs=10) # by default: n_components = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshred\u001b[49m\u001b[38;5;241m.\u001b[39msummary\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shred' is not defined"
     ]
    }
   ],
   "source": [
    "shred.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
