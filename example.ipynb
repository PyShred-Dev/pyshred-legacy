{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from processing.data_manager import SHREDDataManager\n",
    "from models import models\n",
    "import torch\n",
    "import numpy as np\n",
    "from misc.example_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.load('data14fields_npz/EfX_3D.npz')\n",
    "sample = sample[sample.files[0]]\n",
    "sensor_perimeter_walk_coordinates = perimeter_walk(height = sample.shape[0], width = sample.shape[1], timesteps = sample.shape[2], clockwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: EfX_3D.npz\n",
      "Processed: EfZ_3D.npz\n",
      "Processed: Jex_3D.npz\n",
      "Processed: Jey_3D.npz\n",
      "Processed: Jez_3D.npz\n",
      "Processed: ni_3D.npz\n",
      "Processed: phi_3D.npz\n",
      "Processed: Tex_3D.npz\n",
      "Processed: Tez_3D.npz\n",
      "Processed: Ti_3D.npz\n",
      "Processed: Vdix_3D.npz\n",
      "Processed: Vdiy_3D.npz\n",
      "Processed: Vdiz_3D.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialize SHREDDataManager\n",
    "manager = SHREDDataManager(lags=20, train_size=0.7, val_size=0.15, test_size=0.15)\n",
    "\n",
    "# Folder containing .npz files\n",
    "input_folder = \"data14fields_npz\"\n",
    "\n",
    "# Process each .npz file\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".npz\") and filename != 'ne_3D.npz':\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Add the file to the SHREDDataManager\n",
    "        manager.add(\n",
    "            file_path=file_path,\n",
    "            compression=20,\n",
    "            scaling=\"minmax\",\n",
    "            time=np.arange(0, 2000)  # Assuming all files have 2000 timesteps\n",
    "        )\n",
    "        print(f\"Processed: {filename}\")\n",
    "\n",
    "filename = 'ne_3D.npz'\n",
    "file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "manager.add(\n",
    "    file_path=file_path,\n",
    "    random_sensors=3,\n",
    "    stationary_sensors=(7, 9),  # Example coordinates\n",
    "    mobile_sensors=sensor_perimeter_walk_coordinates,\n",
    "    compression=20,\n",
    "    scaling=\"minmax\",\n",
    "    time=np.arange(0, 2000)  # Assuming all files have 2000 timesteps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = manager.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1386, 21, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.reconstructor.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "Error tensor(0.3306)\n",
      "Training epoch 20\n",
      "Error tensor(0.2918)\n",
      "Training epoch 40\n",
      "Error tensor(0.2912)\n",
      "Training epoch 60\n",
      "Error tensor(0.2884)\n",
      "Training epoch 80\n",
      "Error tensor(0.2883)\n",
      "Training epoch 100\n",
      "Error tensor(0.2871)\n",
      "Training epoch 120\n",
      "Error tensor(0.2938)\n",
      "Training epoch 140\n",
      "Error tensor(0.2872)\n",
      "Training epoch 160\n",
      "Error tensor(0.2877)\n",
      "Training epoch 180\n",
      "Error tensor(0.2946)\n",
      "Training epoch 200\n",
      "Error tensor(0.2895)\n",
      "Training epoch 220\n",
      "Error tensor(0.2884)\n",
      "Training epoch 240\n",
      "Error tensor(0.2912)\n",
      "Training epoch 260\n",
      "Error tensor(0.2962)\n",
      "Training epoch 280\n",
      "Error tensor(0.2907)\n",
      "Training epoch 300\n",
      "Error tensor(0.2879)\n",
      "Training epoch 320\n",
      "Error tensor(0.2879)\n",
      "Training epoch 340\n",
      "Error tensor(0.2907)\n",
      "Training epoch 360\n",
      "Error tensor(0.2904)\n",
      "Training epoch 380\n",
      "Error tensor(0.2939)\n",
      "Training epoch 400\n",
      "Error tensor(0.2962)\n",
      "Training epoch 420\n",
      "Error tensor(0.2888)\n",
      "Training epoch 440\n",
      "Error tensor(0.2891)\n",
      "Training epoch 460\n",
      "Error tensor(0.2948)\n",
      "Training epoch 480\n",
      "Error tensor(0.2895)\n",
      "Training epoch 500\n",
      "Error tensor(0.2898)\n",
      "Training epoch 520\n",
      "Error tensor(0.2910)\n",
      "Training epoch 540\n",
      "Error tensor(0.2888)\n",
      "Training epoch 560\n",
      "Error tensor(0.2906)\n",
      "Training epoch 580\n",
      "Error tensor(0.2925)\n",
      "Training epoch 600\n",
      "Error tensor(0.2901)\n",
      "Training epoch 620\n",
      "Error tensor(0.2879)\n",
      "Training epoch 640\n",
      "Error tensor(0.2929)\n",
      "Training epoch 660\n",
      "Error tensor(0.2897)\n",
      "Training epoch 680\n",
      "Error tensor(0.2874)\n",
      "Training epoch 700\n",
      "Error tensor(0.2872)\n",
      "Training epoch 720\n",
      "Error tensor(0.2945)\n",
      "Training epoch 740\n",
      "Error tensor(0.2902)\n",
      "Training epoch 760\n",
      "Error tensor(0.2926)\n",
      "Training epoch 780\n",
      "Error tensor(0.2921)\n",
      "Training epoch 800\n",
      "Error tensor(0.2919)\n",
      "Training epoch 820\n",
      "Error tensor(0.2903)\n",
      "Training epoch 840\n",
      "Error tensor(0.2877)\n",
      "Training epoch 860\n",
      "Error tensor(0.2930)\n",
      "Training epoch 880\n",
      "Error tensor(0.2884)\n",
      "Training epoch 900\n",
      "Error tensor(0.2895)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "shred = models.SHRED(train_set.reconstructor.X.shape[-1], train_set.reconstructor.Y.shape[-1], hidden_size=64, hidden_layers=2, l1=350, l2=400, dropout=0.1).to(device)\n",
    "validation_errors = models.fit(shred, train_set.reconstructor, val_set.reconstructor, batch_size=64, num_epochs=1000, lr=1e-3, verbose=True, patience=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 280)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = shred(test_set.reconstructor.X).detach().cpu().numpy()\n",
    "prediction.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyshred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
